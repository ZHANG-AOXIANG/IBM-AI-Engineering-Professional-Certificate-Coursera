{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Objective</h2><ul><li> How to make a prediction using multiple samples.</li></ul> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Table of Contents\n",
    "In this lab, we will  review how to make a prediction for Linear Regression with Multiple Output. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "<li><a href=\"#ref1\">Class Linear </a></li>\n",
    "\n",
    "<br>\n",
    "<p></p>\n",
    "Estimated Time Needed: <strong>15 min</strong>\n",
    "</div>\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref1\"></a>\n",
    "<a name=\"ref1\"><h2 align=center>Class Linear  </h2></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n%pip install torch==2.8.0+cpu torchvision==0.23.0+cpu torchaudio==2.8.0+cpu \\\n    --index-url https://download.pytorch.org/whl/cpu"
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T07:21:10.236268Z",
     "start_time": "2026-01-11T07:21:09.411207Z"
    }
   },
   "source": [
    "from torch import nn\nimport torch"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the random seed:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T07:21:10.951241Z",
     "start_time": "2026-01-11T07:21:10.913728Z"
    }
   },
   "source": [
    "torch.manual_seed(1)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x304484850>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the random seed:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T07:21:13.451504Z",
     "start_time": "2026-01-11T07:21:13.419153Z"
    }
   },
   "source": [
    "class linear_regression(nn.Module):\n    def __init__(self,input_size,output_size):\n        super(linear_regression,self).__init__()\n        self.linear=nn.Linear(input_size,output_size)\n    def forward(self,x):\n        yhat=self.linear(x)\n        return yhat"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a linear regression  object, as our input and output will be two we set the parameters accordingly \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T07:21:15.522338Z",
     "start_time": "2026-01-11T07:21:15.465050Z"
    }
   },
   "source": [
    "model=linear_regression(1,10)\nmodel(torch.tensor([1.0]))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.7926, -0.3920,  0.1714,  0.0797, -1.0143,  0.5097, -0.0608,  0.5047,\n",
       "         1.0132,  0.1887], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can use the diagram to represent the model or object \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://ibm.box.com/shared/static/icmwnxru7nytlhnq5x486rffea9ncpk7.png\" width=\"600,\" align=\"center\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see the parameters \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T07:21:18.203135Z",
     "start_time": "2026-01-11T07:21:18.122874Z"
    }
   },
   "source": [
    "list(model.parameters())"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.5153],\n",
       "         [-0.4414],\n",
       "         [-0.1939],\n",
       "         [ 0.4694],\n",
       "         [-0.9414],\n",
       "         [ 0.5997],\n",
       "         [-0.2057],\n",
       "         [ 0.5087],\n",
       "         [ 0.1390],\n",
       "         [-0.1224]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.2774,  0.0493,  0.3652, -0.3897, -0.0729, -0.0900,  0.1449, -0.0040,\n",
       "          0.8742,  0.3112], requires_grad=True)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can create a tensor with two rows representing one sample of data\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T07:21:20.300016Z",
     "start_time": "2026-01-11T07:21:20.286292Z"
    }
   },
   "source": [
    "x=torch.tensor([[1.0]])"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can make a prediction \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T07:21:21.685285Z",
     "start_time": "2026-01-11T07:21:21.604841Z"
    }
   },
   "source": [
    "yhat=model(x)\nyhat"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7926, -0.3920,  0.1714,  0.0797, -1.0143,  0.5097, -0.0608,  0.5047,\n",
       "          1.0132,  0.1887]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "each row in the following tensor represents a different sample \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T07:21:24.429989Z",
     "start_time": "2026-01-11T07:21:24.366687Z"
    }
   },
   "source": [
    "X=torch.tensor([[1.0],[1.0],[3.0]])"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can make a prediction using multiple samples \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T07:21:28.307784Z",
     "start_time": "2026-01-11T07:21:28.248269Z"
    }
   },
   "source": [
    "Yhat=model(X)\nYhat"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7926, -0.3920,  0.1714,  0.0797, -1.0143,  0.5097, -0.0608,  0.5047,\n",
       "          1.0132,  0.1887],\n",
       "        [ 0.7926, -0.3920,  0.1714,  0.0797, -1.0143,  0.5097, -0.0608,  0.5047,\n",
       "          1.0132,  0.1887],\n",
       "        [ 1.8232, -1.2748, -0.2164,  1.0184, -2.8972,  1.7091, -0.4722,  1.5222,\n",
       "          1.2912, -0.0561]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following figure represents the operation, where the red and blue  represents the different parameters, and the different shades of green represent  different samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"https://ibm.box.com/shared/static/768cul6pj8hc93uh9ujpajihnp8xdukx.png\" width=\"600,\" align=\"center\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a href=\"https://dataplatform.cloud.ibm.com/registration/stepone?utm_source=skills_network&utm_content=in_lab_content_link&utm_id=Lab-IBMDeveloperSkillsNetwork-DL0110EN-SkillsNetwork&context=cpdaas&apps=data_science_experience%2Cwatson_machine_learning\"><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0110EN-SkillsNetwork/Template/module%201/images/Watson_Studio.png\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About the Authors:  \n",
    "\n",
    " [Joseph Santarcangelo]( https://www.linkedin.com/in/joseph-s-50398b136/) has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n",
    " \n",
    "Other contributors: [Michelle Carey](  https://www.linkedin.com/in/michelleccarey/) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "## Change Log\n",
    "\n",
    "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
    "|---|---|---|---|\n",
    "| 2020-09-23  | 2.0  | Shubham  |  Migrated Lab to Markdown and added to course repo in GitLab |\n",
    "\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h3 align=\"center\"> &#169; IBM Corporation. All rights reserved. <h3/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "prev_pub_hash": "090ab32cbb37a50641bd02927316acbc6d5d1470146fcd05e8693178127aed85"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
